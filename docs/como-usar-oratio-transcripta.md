# ğŸ—£ï¸ Como usar o Oratio Transcripta

Guia completo e didÃ¡tico para instalar, configurar e utilizar o **Oratio Transcripta** no Windows â€” mesmo que vocÃª **nunca tenha usado Python antes**.

---

## ğŸ“˜ O que Ã© o Oratio Transcripta?

**Oratio Transcripta** Ã© uma pipeline em Python para **transcriÃ§Ã£o e anotaÃ§Ã£o automÃ¡tica de Ã¡udio e vÃ­deo**, integrando tecnologias abertas como **Whisper**, **Pyannote**, **WebRTC** e **Silero**.

Ela permite transformar gravaÃ§Ãµes de entrevistas, aulas, palestras ou vÃ­deos em **textos estruturados com metadados FAIR** â€” ou seja, **encontrÃ¡veis, acessÃ­veis, interoperÃ¡veis e reutilizÃ¡veis**.

---

## ğŸ§© Requisitos bÃ¡sicos

| Componente | FunÃ§Ã£o | Onde obter |
|-------------|--------|-------------|
| **Windows 10 ou 11** | Sistema operacional | â€” |
| **Python 3.9 ou superior** (recomenda-se 3.10/3.11) | Linguagem usada pelo projeto | [python.org/downloads](https://www.python.org/downloads/) |
| **FFmpeg** | Processamento e normalizaÃ§Ã£o de Ã¡udio | [ffmpeg.org/download.html](https://ffmpeg.org/download.html) |
| **Visual Studio Build Tools (C++)** | NecessÃ¡rio apenas se `webrtcvad` precisar ser compilado | [visualstudio.microsoft.com/downloads](https://visualstudio.microsoft.com/downloads/) |
| **(Opcional) GPU NVIDIA** | AceleraÃ§Ã£o de processamento | Drivers atualizados |
| **(Opcional) Conta na Hugging Face** | Requerida para modelos `pyannote` | [huggingface.co](https://huggingface.co) |

> ğŸ’¡ **Dica**: Alguns pacotes, como PyTorch, podem demorar a oferecer instaladores para versÃµes muito novas do Python. Priorize 3.10 ou 3.11 para garantir compatibilidade com CUDA e aceleraÃ§Ã£o via GPU.

---

## ğŸ§± Etapa 1 â€“ Instalar o Python

### OpÃ§Ã£o A â€“ InstalaÃ§Ã£o automÃ¡tica (recomendada)
1. Abra o **PowerShell** (menu iniciar â†’ digite `PowerShell`).
2. Execute o comando:

    ```powershell
    winget install Python.Python.3.12
    ```

3. Feche e abra novamente o PowerShell para que o PATH seja atualizado.
4. Verifique se o Python e o `pip` foram instalados corretamente:

    ```powershell
    python --version
    pip --version
    ```

    SaÃ­das esperadas (exemplos):

    ```text
    Python 3.12.x
    pip 24.x.x
    ```

    > âœ… O Oratio Transcripta tambÃ©m funciona com Python 3.9, 3.10 e 3.11. Se jÃ¡ tiver uma dessas versÃµes instaladas, o guia continua vÃ¡lido.

### OpÃ§Ã£o B â€“ InstalaÃ§Ã£o manual
1. Acesse [python.org/downloads](https://www.python.org/downloads/).
2. Baixe o instalador da versÃ£o LTS desejada (3.10 ou 3.11 sÃ£o as mais compatÃ­veis para bibliotecas de IA).
3. Durante a instalaÃ§Ã£o, marque a caixa **â€œAdd Python to PATHâ€**.
4. Conclua a instalaÃ§Ã£o e repita o teste com `python --version` e `pip --version`.

---

## ğŸµ Etapa 2 â€“ Instalar o FFmpeg e adicionar ao PATH

### OpÃ§Ã£o A â€“ InstalaÃ§Ã£o automÃ¡tica
```powershell
winget install Gyan.FFmpeg
```

### OpÃ§Ã£o B â€“ InstalaÃ§Ã£o manual
1. Baixe o pacote ZIP **â€œffmpeg-release-essentialsâ€** para Windows.
2. Extraia o conteÃºdo em `C:\\ffmpeg\\` (o caminho pode ser outro, se preferir).
3. Adicione `C:\\ffmpeg\\bin` ao PATH do Windows:
   - Painel de Controle â†’ Sistema â†’ ConfiguraÃ§Ãµes avanÃ§adas do sistema.
   - Clique em **VariÃ¡veis de Ambiente**.
   - Em **VariÃ¡veis do sistema**, selecione `Path` â†’ **Editar** â†’ **Novo** â†’ `C:\\ffmpeg\\bin` â†’ **OK**.
4. Feche e abra novamente o PowerShell e teste:

   ```powershell
   ffmpeg -version
   ```

   A exibiÃ§Ã£o da versÃ£o confirma que estÃ¡ tudo certo âœ…

---

## ğŸ› ï¸ Etapa 3 â€“ Preparar o ambiente de desenvolvimento

### 3.1 Baixar o cÃ³digo do projeto
1. Acesse o repositÃ³rio oficial (por exemplo, no GitHub).
2. Clique em **Code â†’ Download ZIP**.
3. Extraia o conteÃºdo em uma pasta fÃ¡cil de lembrar, como `C:\\Projetos\\oratiotranscripta`.

> ğŸ’¾ Se preferir usar Git, vocÃª pode executar `git clone https://github.com/...` no PowerShell. O restante das instruÃ§Ãµes permanece igual.

### 3.2 Criar um ambiente virtual (venv)
1. Abra o PowerShell e navegue atÃ© a pasta do projeto:

    ```powershell
    cd C:\\Projetos\\oratiotranscripta
    ```

2. Crie o ambiente virtual:

    ```powershell
    python -m venv .venv
    ```

3. Permita a execuÃ§Ã£o de scripts na sessÃ£o atual (necessÃ¡rio para ativar o venv):

    ```powershell
    Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass -Force
    ```

4. Ative o ambiente virtual:

    ```powershell
    .\\.venv\\Scripts\\Activate.ps1
    ```

    VocÃª verÃ¡ o prefixo `(.venv)` antes do prompt, indicando que o ambiente estÃ¡ ativo.

5. Atualize o `pip` dentro do venv:

    ```powershell
    python -m pip install --upgrade pip
    ```

### 3.3 Instalar dependÃªncias do projeto
```powershell
pip install -U ".[all]"
```

> âš ï¸ Se ocorrer erro ao instalar `webrtcvad`, instale o **Visual Studio Build Tools** com a carga **Desktop development with C++** e repita o comando acima.

---

## ğŸ”‘ Etapa 4 â€“ Criar e configurar sua conta na Hugging Face (para Pyannote)

1. Acesse [huggingface.co](https://huggingface.co) e crie uma conta gratuita.
2. Aceite os termos de uso dos modelos:
   - [`pyannote/voice-activity-detection`](https://huggingface.co/pyannote/voice-activity-detection)
   - [`pyannote/speaker-diarization-3.1`](https://huggingface.co/pyannote/speaker-diarization-3.1)
   - [`pyannote/segmentation-3.0`](https://huggingface.co/pyannote/segmentation-3.0)
3. VÃ¡ em **Settings â†’ Access Tokens** e clique em **Create new token**:
   - Tipo: `Read`
   - Copie o token (ele comeÃ§a com `hf_...`).

### Usando o token
- **OpÃ§Ã£o A â€“ Informar diretamente na linha de comando** (vÃ¡lido apenas para aquela execuÃ§Ã£o):

  ```powershell
  --pyannote-token hf_SEU_TOKEN_AQUI
  ```

- **OpÃ§Ã£o B â€“ Salvar como variÃ¡vel de ambiente** (fica disponÃ­vel em novas sessÃµes):

  ```powershell
  setx HUGGINGFACE_TOKEN "hf_SEU_TOKEN_AQUI"
  setx PYANNOTE_TOKEN "hf_SEU_TOKEN_AQUI"
  ```

  Depois de executar, feche e abra o PowerShell novamente para que as variÃ¡veis sejam carregadas.

---

## ğŸ§ Etapa 5 â€“ Testar o funcionamento da CLI

Com o ambiente virtual ativo (`(.venv)` no prompt), execute:

```powershell
python -m oratiotranscripta --help
python -m oratiotranscripta.annotate --help
```

A exibiÃ§Ã£o das opÃ§Ãµes da CLI confirma que a instalaÃ§Ã£o estÃ¡ pronta ğŸ‰

---

## ğŸš€ SessÃ£o 1 â€“ Transcrever um vÃ­deo do YouTube

Exemplo bÃ¡sico executado apenas na CPU (sem GPU). Ajuste os valores entre aspas conforme o seu caso.

```powershell
python -m oratiotranscripta \
  --source youtube \
  --url "https://www.youtube.com/watch?v=XXXXXXXXXXX" \
  --engine faster-whisper \
  --model medium \
  --lang pt \
  --vad webrtc \
  --diarize basic \
  --export txt srt vtt json \
  --export-json-raw \
  --out .\\saidas\\youtube \
  --run-id youtube_demo \
  --manifest
```

### ExplicaÃ§Ã£o das opÃ§Ãµes principais

| Flag | FunÃ§Ã£o |
|------|--------|
| `--source youtube` | Informa que o Ã¡udio serÃ¡ baixado do YouTube. |
| `--url` | Link do vÃ­deo a ser processado. |
| `--engine faster-whisper` | TranscriÃ§Ã£o otimizada (usa CTranslate2). |
| `--model medium` | Define o modelo de ASR (quanto maior, mais preciso e lento). |
| `--lang pt` | ForÃ§a o idioma portuguÃªs. |
| `--vad webrtc` | DetecÃ§Ã£o de fala estÃ¡vel e eficiente em CPU. |
| `--diarize basic` | SeparaÃ§Ã£o simples de falantes. |
| `--export txt srt vtt json` | Gera mÃºltiplos formatos de transcriÃ§Ã£o. |
| `--export-json-raw` | Gera o arquivo bruto `*.raw_segments.jsonl`. |
| `--out .\\saidas\\youtube` | Define a pasta base onde os resultados serÃ£o salvos. |
| `--run-id youtube_demo` | Define manualmente o identificador da execuÃ§Ã£o (subpasta). |
| `--manifest` | Gera `run_manifest.json` automaticamente dentro da pasta da execuÃ§Ã£o. |

> ğŸ—‚ï¸ **Onde os arquivos sÃ£o salvos?** Sempre Ã© criada uma subpasta com o valor de `--run-id` (ou um timestamp automÃ¡tico). Dentro dela, os arquivos usam o nome da pasta de saÃ­da (`youtube` no exemplo) como prefixo.

### Resultado esperado

```text
.\\saidas\\youtube\\youtube_demo\\
â”œâ”€ logs\\pipeline.log
â”œâ”€ run_manifest.json
â”œâ”€ youtube.json
â”œâ”€ youtube.raw_segments.jsonl
â”œâ”€ youtube.srt
â”œâ”€ youtube.txt
â””â”€ youtube.vtt
```

Se vocÃª nÃ£o informar `--run-id`, o Oratio Transcripta criarÃ¡ algo como `20240101-120000`. O manifesto Ã© salvo automaticamente como `<pasta_saida>/<run_id>/run_manifest.json`.

---

## ğŸ§‘â€ğŸ’» SessÃ£o 2 â€“ Transcrever um arquivo local

```powershell
python -m oratiotranscripta \
  --source local \
  --path "D:\\MeusAudios\\Aula1.mp3" \
  --engine faster-whisper \
  --model medium \
  --lang pt \
  --vad webrtc \
  --diarize basic \
  --export txt srt vtt \
  --out .\\saidas\\local \
  --run-id aula1 \
  --manifest
```

Para usar GPU (CUDA), acrescente `--device cuda`. Se quiser acelerar ainda mais, combine com `--compute-type float16`.

Resultado organizado em `.\\saidas\\local\\aula1\\`, com arquivos `local.txt`, `local.srt`, `local.vtt`, `local.raw_segments.jsonl` e `run_manifest.json`.

---

## ğŸ“ SessÃ£o 3 â€“ Anotar uma transcriÃ§Ã£o revisada (EstÃ¡gio B)

ApÃ³s revisar manualmente o arquivo `.txt`, `.srt` ou `.vtt` gerado na etapa anterior, execute:

```powershell
python -m oratiotranscripta.annotate \
  --transcript .\\edited\\entrevista.srt \
  --format auto \
  --metadata .\\edited\\entrevista.yml \
  --raw-json .\\saidas\\youtube\\youtube_demo\\youtube.raw_segments.jsonl \
  --export-format jsonl \
  --out .\\publish\\entrevista.annotated.jsonl \
  --manifest
```

Esse comando:

- Gera um arquivo `.jsonl` anotado com IDs estÃ¡veis.
- Cria um manifesto FAIR (`entrevista.annotated.manifest.json`) com hashes, mÃ©tricas e proveniÃªncia.
- Permite rastrear o caminho entre o Ã¡udio original e o texto revisado.

> ğŸ” **Manifesto da anotaÃ§Ã£o**: quando `--manifest` Ã© utilizado na CLI de anotaÃ§Ã£o, o arquivo Ã© salvo ao lado da saÃ­da final, com sufixo `.manifest.json` (por exemplo, `entrevista.annotated.manifest.json`).

---

## âš–ï¸ SessÃ£o 4 â€“ Entendendo os estÃ¡gios da pipeline

| EstÃ¡gio | FunÃ§Ã£o | SaÃ­das principais |
|---------|--------|-------------------|
| **A â€“ TranscriÃ§Ã£o** | Processa o Ã¡udio/vÃ­deo, detecta falas, cria arquivos TXT/SRT/VTT, JSON e JSONL. | `*.txt`, `*.srt`, `*.vtt`, `*.json`, `*.raw_segments.jsonl`, `run_manifest.json` |
| **B â€“ AnotaÃ§Ã£o** | Integra revisÃ£o humana, gera dataset anotado e manifesto FAIR. | `*.annotated.jsonl`, `*.annotated.manifest.json` |

---

## ğŸ§­ Como localizar ou definir o `run_id`

- **Definir manualmente**: use `--run-id nome_da_execucao` para criar uma subpasta previsÃ­vel.
- **Gerado automaticamente**: se nÃ£o informar a flag, o Oratio Transcripta cria um `run_id` com data e hora (`YYYYMMDD-HHMMSS`). Verifique as subpastas dentro do diretÃ³rio definido em `--out` para descobrir o valor.
- **Reutilizar artefatos**: nos comandos que precisam de `--raw-json` ou `--manifest`, sempre inclua o caminho completo atÃ© essa subpasta, por exemplo: `.\\saidas\\youtube\\20240101-120000\\youtube.raw_segments.jsonl`.

---

## ğŸ§­ SessÃ£o 5 â€“ Problemas comuns (troubleshooting)

| Erro ou situaÃ§Ã£o | SoluÃ§Ã£o |
|------------------|---------|
| â€œexecuÃ§Ã£o de scripts foi desabilitadaâ€ | Rode `Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass -Force` antes de ativar o venv. |
| `ffmpeg` nÃ£o reconhecido | Reabra o PowerShell e confirme se `C:\\ffmpeg\\bin` (ou equivalente) estÃ¡ no PATH. |
| Falha na instalaÃ§Ã£o de `webrtcvad` | Instale o Visual Studio Build Tools (Desktop development with C++) e repita `pip install -U ".[all]"`. |
| Erro 401/403 ao usar Pyannote | Aceite os termos dos modelos na Hugging Face e confirme se o token estÃ¡ correto. |
| TranscriÃ§Ã£o muito lenta em CPU | Use `--engine faster-whisper`, reduza o modelo (`small`, `base`) ou utilize uma GPU com `--device cuda`. |

---

## ğŸ’¡ Dicas Ãºteis

- Organize seus resultados em subpastas por projeto ou gravaÃ§Ã£o.
- Guarde sempre os arquivos brutos (`*.raw_segments.jsonl`) e `run_manifest.json` â€” eles sÃ£o a â€œassinatura digitalâ€ da execuÃ§Ã£o.
- Para publicar resultados como dataset FAIR, inclua:
  - `metadata.yml`
  - `run_manifest.json`
  - `*.annotated.jsonl`
  - LicenÃ§a (por exemplo, `LICENSE` ou `CC-BY-4.0.txt`)
- Se quiser acompanhar palavra a palavra, acrescente `--words --align` ao comando de transcriÃ§Ã£o (requer modelos compatÃ­veis, como WhisperX).

---

## ğŸ“‚ Estrutura tÃ­pica de projeto

```text
oratiotranscripta/
â”‚
â”œâ”€ output/
â”‚   â””â”€ youtube_demo/
â”‚       â”œâ”€ logs/
â”‚       â”‚   â””â”€ pipeline.log
â”‚       â”œâ”€ run_manifest.json
â”‚       â”œâ”€ youtube.json
â”‚       â”œâ”€ youtube.raw_segments.jsonl
â”‚       â”œâ”€ youtube.srt
â”‚       â”œâ”€ youtube.txt
â”‚       â””â”€ youtube.vtt
â”‚
â”œâ”€ edited/
â”‚   â”œâ”€ entrevista.srt
â”‚   â””â”€ metadata.yml
â”‚
â””â”€ publish/
    â”œâ”€ entrevista.annotated.jsonl
    â””â”€ entrevista.annotated.manifest.json
```

---

## ğŸ“– Recursos avanÃ§ados

- **Alinhamento palavra a palavra (WhisperX):** adicione `--align --words --export json` durante a transcriÃ§Ã£o.
- **Uso do Pyannote com token:** combine `--vad pyannote --diarize pyannote --pyannote-token hf_SEU_TOKEN` para diarizaÃ§Ã£o avanÃ§ada.
- **MÃ©tricas e metadados automÃ¡ticos:** os manifestos (`run_manifest.json` e `*.annotated.manifest.json`) incluem:
  - Hashes SHA256
  - Tempo total e nÃºmero de falas
  - Modelos e versÃµes utilizados
  - Caminhos relativos dos arquivos

---

## ğŸŒ Plataformas suportadas

| Sistema | Compatibilidade | ObservaÃ§Ãµes |
|---------|-----------------|-------------|
| **Windows 10/11** | âœ… Completo | Guia principal. |
| **macOS** | âœ… (CPU) | Instale via Homebrew: `brew install python ffmpeg`. |
| **Linux (Ubuntu/Debian)** | âœ… | `sudo apt install python3-venv ffmpeg git`. |

---

## ğŸ Pronto para comeÃ§ar!

Agora vocÃª pode:

- Transcrever entrevistas e vÃ­deos;
- Revisar manualmente e gerar datasets anotados;
- Exportar metadados FAIR para reprodutibilidade completa;
- Compartilhar resultados de forma transparente, valorizando a palavra, a memÃ³ria e a pesquisa.

O **Oratio Transcripta** vai alÃ©m de uma ferramenta de transcriÃ§Ã£o â€” Ã© uma proposta de ciÃªncia aberta aplicada Ã  fala.
